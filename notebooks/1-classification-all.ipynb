{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chemical and physicochemical nonlinear classification tasks\n",
    "\n",
    "**Author**: M.G. Baltussen\n",
    "\n",
    "**Estimated runtime**: 15 minutes \n",
    "\n",
    "**Generated output**: \n",
    "- `plots/classification_inputs_example.svg` (manuscript fig. 2)\n",
    "- `plots/classification_task_example.svg` (manuscript fig. 2)\n",
    "- `plots/classification_output_example.svg` (manuscript fig. 2)\n",
    "- `plots/sensor_tasks.svg` (manuscript fig. 2)\n",
    "- `plots/sensor_inputs.svg` (manuscript fig. 2)\n",
    "- `plots/SI_sensor_inputs.svg` (SI fig. 9)\n",
    "- `plots/sensor_results.svg` (manuscript fig. 2)\n",
    "- `plots/SI_sensor_results_extended.svg` (SI fig. 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.preprocessing as preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import style\n",
    "style.set_style()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extends_pH = (6.0, 8.5)\n",
    "extends_T = (25.0, 55.0)\n",
    "extends_s1 = (40.0, 100.0)\n",
    "extends_s2 = (15.0, 75.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dropped_columns = ['author', 'exp_code', 'type', 'exp_date', 'measurement_date', 'measurement_time', 'sample', 'flowrate',\n",
    "                   'TKIFKI', 'TTMHPRL',\n",
    "                   'T', 'pH', 'SSVRWWSDDEWRW', \n",
    "                   'CCF(pS)WRCRC', 'IYPFVEPI'\n",
    "                   ]\n",
    "\n",
    "df_data_S = pd.read_csv(\"../data/RC_S1_S2.csv\", index_col=0).drop(columns=dropped_columns).rename(columns = {\n",
    "                        'AVNIPFKVHLRCKAAFC': 'S1',\n",
    "                        'CCFSWRCRC': 'S2'\n",
    "                        })\n",
    "# Seperate dataset inputs and outputs\n",
    "U_chem = df_data_S[['S1','S2']] # inputs\n",
    "X_chem = df_data_S.drop(columns=['S1', 'S2']) # outputs\n",
    "\n",
    "scaler_s1_s2 = preprocessing.MinMaxScaler().fit(pd.DataFrame({'S1': extends_s1, 'S2': extends_s2}))\n",
    "scaler_T_s2 = preprocessing.MinMaxScaler().fit(pd.DataFrame({\"T\": extends_T, \"S2\": extends_s2}))\n",
    "scaler_ph_s2 = preprocessing.MinMaxScaler().fit(pd.DataFrame({\"pH\": extends_pH, \"S2\": extends_s2}))\n",
    "scaler_ph_T = preprocessing.MinMaxScaler().fit(pd.DataFrame({\"pH\": extends_pH, \"T\": extends_T}))\n",
    "U_s = scaler_s1_s2.transform(U_chem)\n",
    "X_s = preprocessing.StandardScaler().fit_transform(X_chem)\n",
    "\n",
    "dropped_columns = ['author', 'exp_code', 'type', 'exp_date', 'measurement_date', 'measurement_time', 'sample', 'flowrate',\n",
    "                   'TKIFKI', 'TTMHPRL',\n",
    "                   'SSVRWWSDDEWRW', \n",
    "                   'CCF(pS)WRCRC', 'IYPFVEPI'\n",
    "                   ]\n",
    "\n",
    "\n",
    "df_T_S2 = pd.read_csv(\"../data/RC_T_S2.csv\", index_col=0).drop(columns=dropped_columns).rename(columns = {\n",
    "                        'AVNIPFKVHLRCKAAFC': 'S1',\n",
    "                        'CCFSWRCRC': 'S2'\n",
    "                        }).drop(columns=['pH', 'S1'])\n",
    "df_pH_S2 = pd.read_csv(\"../data/RC_pH_S2.csv\", index_col=0).drop(columns=dropped_columns).rename(columns = {\n",
    "                        'AVNIPFKVHLRCKAAFC': 'S1',\n",
    "                        'CCFSWRCRC': 'S2'\n",
    "                        }).drop(columns=['T', 'S1'])\n",
    "df_pH_T = pd.read_csv(\"../data/RC_pH_T.csv\", index_col=0).drop(columns=dropped_columns).rename(columns = {\n",
    "                        'AVNIPFKVHLRCKAAFC': 'S1',\n",
    "                        'CCFSWRCRC': 'S2'\n",
    "                        }).drop(columns=['S1', 'S2'])\n",
    "\n",
    "# Seperate dataset inputs and outputs\n",
    "U_T_S2 = df_T_S2[['T','S2']] # inputs\n",
    "X_T_S2 = df_T_S2.drop(columns=['T', 'S2']) # outputs\n",
    "U_pH_S2 = df_pH_S2[['pH','S2']] # inputs\n",
    "X_pH_S2 = df_pH_S2.drop(columns=['pH', 'S2']) # outputs\n",
    "U_pH_T = df_pH_T[['pH','T']] # inputs\n",
    "X_pH_T = df_pH_T.drop(columns=['pH', 'T']) # outputs\n",
    "\n",
    "U_T_S2 = scaler_T_s2.transform(U_T_S2)\n",
    "U_pH_S2 = scaler_ph_s2.transform(U_pH_S2)\n",
    "U_pH_T = scaler_ph_T.transform(U_pH_T)\n",
    "X_T_S2 = preprocessing.StandardScaler().fit_transform(X_T_S2)\n",
    "X_pH_S2 = preprocessing.StandardScaler().fit_transform(X_pH_S2)\n",
    "X_pH_T = preprocessing.StandardScaler().fit_transform(X_pH_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Classification task definitions \"\"\"\n",
    "from collections import OrderedDict\n",
    "\n",
    "y_xor = lambda U: np.logical_xor(U[:,0] < 0.5, U[:,1] < 0.5)\n",
    "y_circle = lambda U: ((U[:,0]-0.5)**2 + (U[:,1]-0.5)**2) < 0.125\n",
    "y_hourglass = lambda U: ((U[:,0] < U[:,1]) & (U[:,0] < (1 - U[:,1]))) | ((U[:,0] > U[:,1]) & (U[:,0] > (1 - U[:,1])))\n",
    "\n",
    "N_POINTS = 1000\n",
    "EXTENDS = (-0.1, 1.1)\n",
    "xs, ys = np.meshgrid(np.linspace(*EXTENDS, N_POINTS), np.linspace(*EXTENDS, N_POINTS))\n",
    "z_xor = np.logical_xor(xs < 0.5, ys < 0.5)\n",
    "z_circle = ((xs-0.5)**2 + (ys-0.5)**2) < 0.125\n",
    "\n",
    "z_hourglass = ((xs < ys) & (xs < (1 - ys))) | ((xs > ys) & (xs > (1 - ys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Extended Classification task definitions \"\"\"\n",
    "from collections import OrderedDict\n",
    "\n",
    "def triangle(x, y):\n",
    "   z_triangle_b1 =  (y < x/3 + 1/3)\n",
    "   z_triangle_b2 = (x < y/3 + 1/3)\n",
    "   z_triangle_b3 = (y < -x + 1) \n",
    "   z_triangle_1 = -1*np.logical_and(z_triangle_b1, z_triangle_b3)\n",
    "   z_triangle_2 = 0.0* np.logical_and(z_triangle_b2, ~z_triangle_b1)\n",
    "   z_triangle_3 = np.logical_and(~z_triangle_b2, ~z_triangle_b3)\n",
    "   z_triangle = z_triangle_1 + z_triangle_2 + z_triangle_3\n",
    "   return z_triangle\n",
    "\n",
    "y_and = lambda U: np.logical_and(U[:,0] > 0.5, U[:,1] > 0.5)\n",
    "y_or = lambda U: np.logical_or(U[:,0] > 0.5, U[:,1] > 0.5)\n",
    "y_triangle = lambda U: triangle(U[:,0], U[:,1])\n",
    "y_checker = lambda U: np.logical_xor((U[:,0] // 0.33333)%2, (U[:,1] // 0.33333)%2)\n",
    "\n",
    "y_eye = lambda U: 1*(((U[:,0]-0.5)**2 + (U[:,1]-0.5)**2) < 0.16) - 1*(((U[:,0]-0.5)**2 + (U[:,1]-0.5)**2) < 0.04)\n",
    "y_dots = lambda U: 1*(((U[:,0]-0.3)**2 + (U[:,1]-0.3)**2) < 0.05) + 1*(((U[:,0]-0.7)**2 + (U[:,1]-0.7)**2) < 0.05)\n",
    "y_sin = lambda U: U[:,1] > 0.5 + 0.5*np.sin(U[:,0]*np.pi*2/0.8 - np.pi/4)\n",
    "\n",
    "y_extended = OrderedDict(\n",
    "   AND = y_and,\n",
    "   OR = y_or,\n",
    "   Triangle = y_triangle,\n",
    "   XOR= y_xor,\n",
    "   Hourglass= y_hourglass,\n",
    "   Checkers = y_checker,\n",
    "   Circle= y_circle,\n",
    "   Sine= y_sin,\n",
    "   Concentric = y_eye,\n",
    "   Dots = y_dots,\n",
    ")\n",
    "\n",
    "N_POINTS = 1000\n",
    "EXTENDS = (-0.1, 1.1)\n",
    "xs, ys = np.meshgrid(np.linspace(*EXTENDS, N_POINTS), np.linspace(*EXTENDS, N_POINTS))\n",
    "\n",
    "z_and = np.logical_and(xs > 0.5, ys > 0.5)\n",
    "z_or = np.logical_or(xs > 0.5, ys > 0.5)\n",
    "z_triangle = triangle(xs, ys)\n",
    "z_checker = np.logical_xor((xs // 0.33333)%2, (ys // 0.33333)%2)\n",
    "\n",
    "z_eye = 1*(((xs-0.5)**2 + (ys-0.5)**2) < 0.16) - 1*(((xs-0.5)**2 + (ys-0.5)**2) < 0.04)\n",
    "z_dots = 1*(((xs-0.3)**2 + (ys-0.3)**2) < 0.05) + 1*(((xs-0.7)**2 + (ys-0.7)**2) < 0.05)\n",
    "z_sin =  ys > 0.5 + 0.5*np.sin(xs*np.pi*2/0.8 - np.pi/4)\n",
    "\n",
    "z_extended = OrderedDict(\n",
    "   AND  = z_and,\n",
    "   OR  = z_or,\n",
    "   Triangle  = z_triangle,\n",
    "   XOR = z_xor,\n",
    "   Hourglass = z_hourglass,\n",
    "   Checkers = z_checker,\n",
    "   Circle = z_circle,\n",
    "   Sine = z_sin,\n",
    "   Concentric  = z_eye,\n",
    "   Dots  = z_dots,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(0.6, 0.6),\n",
    "                        constrained_layout=False)\n",
    "\n",
    "axes.scatter(*U_s.T, s=4, c='C2')\n",
    "axes.scatter(*U_s[10], s=8, c='C2', ec=style.nord_base.dark[0])\n",
    "axes.set_xlabel(r\"$U_1$\", va='bottom')\n",
    "axes.set_ylabel(r\"$U_2$\", va='top')\n",
    "axes.set_xticks([0, 1])\n",
    "axes.set_yticks([0, 1])\n",
    "sns.despine(top=False, right=False)\n",
    "plt.savefig(\"../plots/classification_inputs_example.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(0.4, 0.4),\n",
    "                        constrained_layout=True)\n",
    "\n",
    "ax.imshow(z_circle, origin=\"lower\", aspect=\"auto\", interpolation=\"none\",\n",
    "        extent=(*EXTENDS, *EXTENDS), alpha=0.5,\n",
    "        cmap=sns.color_palette(\"vlag\", as_cmap=True),\n",
    "    )\n",
    "sns.despine(ax=ax, top=False, right=False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])\n",
    "plt.savefig(\"../plots/classification_task_example.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(0.6, 0.6),\n",
    "                        constrained_layout=False)\n",
    "axes.imshow(z_circle, origin=\"lower\", aspect=\"auto\", interpolation=\"none\",\n",
    "        extent=(*EXTENDS, *EXTENDS), alpha=0.25,\n",
    "        cmap=sns.color_palette(\"vlag\", as_cmap=True),\n",
    "    )\n",
    "axes.scatter(*U_s.T, s=4, c=style.nord_base.light[0], ec=style.nord_base.dark[0], lw=0.2)\n",
    "axes.scatter(*U_s[10], s=8, c='C3', ec=style.nord_base.dark[0])\n",
    "axes.set_xlabel(r\"$U_1$\", va='bottom')\n",
    "axes.set_ylabel(r\"$U_2$\", va='top')\n",
    "axes.set_xticks([0, 1])\n",
    "axes.set_yticks([0, 1])\n",
    "axes.set_xlim([0,1])\n",
    "axes.set_ylim([0,1])\n",
    "sns.despine(top=False, right=False)\n",
    "plt.savefig(\"../plots/classification_output_example.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, gaussian_process, neural_network, linear_model\n",
    "from pyrcn.extreme_learning_machine import ELMClassifier\n",
    "from sklearn import metrics, model_selection\n",
    "\n",
    "classifiers = {\n",
    "    \"LSVC\": svm.SVC(max_iter=10_000, tol=1e-4, kernel='linear'),\n",
    "    \"SVC\": svm.SVC(max_iter=10_000, tol=1e-4),\n",
    "    \"GP\": gaussian_process.GaussianProcessClassifier(),\n",
    "    \"MLP\": neural_network.MLPClassifier(max_iter=10_000),\n",
    "    \"ELM\": ELMClassifier(regressor=linear_model.Ridge()),\n",
    "}\n",
    "N_classifiers = len(classifiers)\n",
    "classifier_labels = ['ERC'] + list(classifiers.keys())\n",
    "\n",
    "def classification_task(U, X, y_task, n_repeats=10):\n",
    "    train_scores = dict()\n",
    "    test_scores = dict()\n",
    "    test_scores_std = dict()\n",
    "\n",
    "    N_inputs = U.shape[0] # Number of different inputs\n",
    "\n",
    "    reg = svm.SVC(max_iter=10_000, tol=1e-4, kernel='linear')\n",
    "    scores = model_selection.cross_validate(\n",
    "        reg, X, y_task,\n",
    "        scoring = metrics.make_scorer(metrics.matthews_corrcoef),\n",
    "        cv = model_selection.RepeatedStratifiedKFold(\n",
    "            n_splits=N_inputs//5, n_repeats=n_repeats,\n",
    "        ),\n",
    "        n_jobs=1,\n",
    "        return_estimator=True, return_train_score=True, return_indices=True\n",
    "    )\n",
    "\n",
    "    est_predictions = [\n",
    "        est.predict(X[scores[\"indices\"][\"test\"][i]])\n",
    "        for i, est in enumerate(scores[\"estimator\"])\n",
    "    ]\n",
    "    from collections import defaultdict\n",
    "\n",
    "    est_predictions_by_idx = defaultdict(list)\n",
    "    for e_i, (idxs, preds) in enumerate(\n",
    "        zip(scores[\"indices\"][\"test\"], est_predictions)\n",
    "    ):\n",
    "        for idx, pred in zip(idxs, preds):\n",
    "            est_predictions_by_idx[idx].append(pred)\n",
    "\n",
    "    est_scores_by_idx = {\n",
    "        k: np.equal(y_task[k], v).mean() for k, v in est_predictions_by_idx.items()\n",
    "    }\n",
    "\n",
    "    idx = np.array(list(est_scores_by_idx.keys()))\n",
    "    vals = np.array(list(est_scores_by_idx.values()))\n",
    "    accuracies = np.zeros(X.shape[0])\n",
    "    accuracies[idx] = vals\n",
    "\n",
    "    reg.fit(X, y_task)\n",
    "    y_predict = reg.predict(X)\n",
    "    train_scores['ERC'] = reg.score(X, y_task)\n",
    "    test_scores['ERC'] = (scores['test_score'].mean() + 1)/2\n",
    "    test_scores_std['ERC'] = ((scores['test_score']+1)/2).std()\n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        scores = model_selection.cross_validate(\n",
    "            clf, U, y_task,\n",
    "            scoring = metrics.make_scorer(metrics.matthews_corrcoef),\n",
    "            cv = model_selection.RepeatedStratifiedKFold(\n",
    "                n_splits=N_inputs//5, n_repeats=n_repeats,\n",
    "            ),\n",
    "            n_jobs=1,\n",
    "            return_estimator=True, return_train_score=True, return_indices=True\n",
    "        )\n",
    "\n",
    "        clf.fit(U, y_task)\n",
    "        train_scores[name] = clf.score(U, y_task)\n",
    "        test_scores[name] = (scores['test_score'].mean()+1)/2\n",
    "        test_scores_std[name] = ((scores['test_score']+1)/2).std()/np.sqrt(len(scores['test_score']))\n",
    "\n",
    "    return y_predict, accuracies, train_scores, test_scores, test_scores_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(axes, U, z_train, test_scores, test_scores_std, accuracies):\n",
    "    ax0 = axes[0]\n",
    "    cmap = sns.color_palette(\"blend:#BF616A,#EBCB8B,#8FBCBB\", as_cmap=True, n_colors=10)\n",
    "    ax0.imshow(\n",
    "        z_train,\n",
    "        origin=\"lower\",\n",
    "        aspect=\"auto\",\n",
    "        interpolation=\"none\",\n",
    "        extent=(*EXTENDS, *EXTENDS),\n",
    "        alpha=0.25,\n",
    "        cmap=sns.color_palette(\"vlag\", as_cmap=True),\n",
    "    )\n",
    "    ax0.scatter(\n",
    "        *U.T,\n",
    "        s=(2.5**2),\n",
    "        c=accuracies,\n",
    "        lw=0.1,\n",
    "        ec=\"black\",\n",
    "        zorder=10,\n",
    "        cmap=cmap,\n",
    "        norm=plt.Normalize(0.0, 1.0),\n",
    "    )\n",
    "\n",
    "    # ax0.set_title(k, fontdict={\"fontweight\": \"bold\"})\n",
    "    ax0.set_xlim(*EXTENDS)\n",
    "    ax0.set_ylim(*EXTENDS)\n",
    "    ax0.set_xticks([])\n",
    "    ax0.set_yticks([])\n",
    "\n",
    "    ax = axes[1]\n",
    "    ax.bar(\n",
    "        np.arange(0, N_classifiers + 1),\n",
    "        width=0.5, height=[t for t in test_scores.values()],\n",
    "        color='C0',\n",
    "        linewidth=0.5, edgecolor=style.nord_base.dark[0],\n",
    "        label=classifier_labels\n",
    "    )\n",
    "    ax.errorbar(np.arange(0, N_classifiers + 1), \n",
    "                     [t for t in test_scores.values()],\n",
    "                     [t for t in test_scores_std.values()],\n",
    "                     fmt='o', color=style.nord_base.dark[0],\n",
    "                     ms=1,\n",
    "                     )\n",
    "    ax.set_xticks(np.arange(0, N_classifiers+1))\n",
    "    ax.set_xticklabels(classifier_labels, rotation='vertical', ha='center')[0].set_weight('bold')\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.axhline(test_scores['ERC'], ls='--', lw=0.5, color=style.nord_base.dark[0])\n",
    "    ax.set_yticks([0, 0.5, 1.0])\n",
    "    ax.set_ylabel(r\"$\\Phi$ acc.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(1.8, 0.8), constrained_layout=True)\n",
    "\n",
    "axes[0].imshow(z_xor, origin=\"lower\", aspect=\"auto\", interpolation=\"none\",\n",
    "        extent=(*EXTENDS, *EXTENDS), alpha=0.5,\n",
    "        cmap=sns.color_palette(\"vlag\", as_cmap=True),\n",
    "    )\n",
    "sns.despine(ax=axes[0], top=False, right=False)\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_yticks([])\n",
    "axes[0].set_xlim(*EXTENDS)\n",
    "axes[0].set_ylim(*EXTENDS)\n",
    "\n",
    "\n",
    "axes[1].imshow(z_circle, origin=\"lower\", aspect=\"auto\", interpolation=\"none\",\n",
    "        extent=(*EXTENDS, *EXTENDS), alpha=0.5,\n",
    "        cmap=sns.color_palette(\"vlag\", as_cmap=True),\n",
    "    )\n",
    "sns.despine(ax=axes[1], top=False, right=False)\n",
    "axes[1].set_xticks([])\n",
    "axes[1].set_yticks([])\n",
    "axes[1].set_xlim(*EXTENDS)\n",
    "axes[1].set_ylim(*EXTENDS)\n",
    "\n",
    "\n",
    "axes[2].imshow(z_hourglass, origin=\"lower\", aspect=\"auto\", interpolation=\"none\",\n",
    "        extent=(*EXTENDS, *EXTENDS), alpha=0.5,\n",
    "        cmap=sns.color_palette(\"vlag\", as_cmap=True),\n",
    "    )\n",
    "sns.despine(ax=axes[2], top=False, right=False)\n",
    "axes[2].set_xticks([])\n",
    "axes[2].set_yticks([])\n",
    "axes[2].set_xlim(*EXTENDS)\n",
    "axes[2].set_ylim(*EXTENDS)\n",
    "\n",
    "axes[0].set_title('XOR')\n",
    "axes[1].set_title('Circle')\n",
    "axes[2].set_title('Hourglass')\n",
    "\n",
    "plt.savefig(f\"../plots/sensor_tasks.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(0.7, 2.0), constrained_layout=False)\n",
    "\n",
    "axes[0].scatter(*U_s.T, s=1.5**2)\n",
    "axes[1].scatter(*U_pH_T.T, s=1.5**2)\n",
    "\n",
    "axes[0].set_xlabel(r\"S1 ($\\mu M$)\", va='bottom')\n",
    "axes[0].set_ylabel(r\"S2 ($\\mu M$)\", va='top')\n",
    "axes[0].set_xlim(*EXTENDS)\n",
    "axes[0].set_ylim(*EXTENDS)\n",
    "axes[0].set_xticks([0, 1], extends_s1)\n",
    "axes[0].set_yticks([0, 1], extends_s2)\n",
    "\n",
    "axes[1].set_xlabel(r\"pH\", va='bottom')\n",
    "axes[1].set_ylabel(r\"T ($\\degree C$)\", va='top')\n",
    "axes[1].set_xlim(*EXTENDS)\n",
    "axes[1].set_ylim(*EXTENDS)\n",
    "axes[1].set_xticks([0, 1], extends_pH)\n",
    "axes[1].set_yticks([0, 1], extends_T)\n",
    "\n",
    "axy = axes[0].twiny()\n",
    "axy.set_xticks([0, 1])\n",
    "axy.set_xlim(-0.05, 1.05)\n",
    "axy.set_xlabel(r\"$U_1$\")\n",
    "\n",
    "axx = axes[0].twinx()\n",
    "axx.set_yticks([0, 1])\n",
    "axx.set_ylim(-0.05, 1.05)\n",
    "axx.set_ylabel(r\"$U_2$\")\n",
    "axy.xaxis.set_label_coords(0.5, 1.1)\n",
    "axx.yaxis.set_label_coords(1.1, 0.5)\n",
    "\n",
    "axy = axes[1].twiny()\n",
    "axy.set_xticks([0, 1])\n",
    "axy.set_xlim(-0.05, 1.05)\n",
    "axy.set_xlabel(r\"$U_1$\")\n",
    "\n",
    "axx = axes[1].twinx()\n",
    "axx.set_yticks([0, 1])\n",
    "axx.set_ylim(-0.05, 1.05)\n",
    "axx.set_ylabel(r\"$U_2$\")\n",
    "axy.xaxis.set_label_coords(0.5, 1.1)\n",
    "axx.yaxis.set_label_coords(1.1, 0.5)\n",
    "\n",
    "plt.subplots_adjust(hspace=.8, wspace=0.2)\n",
    "sns.despine(top=False, right=False)\n",
    "\n",
    "plt.savefig(f\"../plots/sensor_inputs.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(1.0, 1.8), constrained_layout=True)\n",
    "\n",
    "axes[0].scatter(*U_T_S2.T, s=1.5**2)\n",
    "axes[1].scatter(*U_pH_S2.T, s=1.5**2)\n",
    "\n",
    "axes[0].set_xlabel(r\"T ($\\degree C$)\", va='bottom')\n",
    "axes[0].set_ylabel(r\"S2 ($\\mu M$)\", va='top')\n",
    "axes[0].set_xlim(*EXTENDS)\n",
    "axes[0].set_ylim(*EXTENDS)\n",
    "axes[0].set_xticks([0, 1], extends_T)\n",
    "axes[0].set_yticks([0, 1], extends_s2)\n",
    "\n",
    "axes[1].set_xlabel(r\"pH\", va='bottom')\n",
    "axes[1].set_ylabel(r\"S2 ($\\mu M$)\", va='top')\n",
    "axes[1].set_xlim(*EXTENDS)\n",
    "axes[1].set_ylim(*EXTENDS)\n",
    "axes[1].set_xticks([0, 1], extends_pH)\n",
    "axes[1].set_yticks([0, 1], extends_s2)\n",
    "\n",
    "# plt.subplots_adjust(hspace=1.2, wspace=0.5)\n",
    "\n",
    "plt.savefig(f\"../plots/SI_sensor_inputs.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores_all = [[None, None], [None, None], [None, None]]\n",
    "test_scores_std_all = [[None, None], [None, None], [None, None]]\n",
    "accuracies_all = [[None, None], [None, None], [None, None]]\n",
    "for i, (y_task, z_task) in enumerate(zip([y_xor, y_circle, y_hourglass], [z_xor, z_circle, z_hourglass])):\n",
    "    for j, (u, x) in enumerate(zip([U_s, U_pH_T], [X_s, X_pH_T])):\n",
    "        y_pred, accuracies, train_scores, test_scores, test_scores_std = classification_task(u, x, y_task=y_task(u), n_repeats=10,)\n",
    "        test_scores_all[i][j] = test_scores\n",
    "        test_scores_std_all[i][j] = test_scores_std\n",
    "        accuracies_all[i][j] = accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,3, figsize=(2.6, 2.6), constrained_layout=False, gridspec_kw={'height_ratios':[2,1,2,1]})\n",
    "for i, (y_task, z_task) in enumerate(zip([y_xor, y_circle, y_hourglass], [z_xor, z_circle, z_hourglass])):\n",
    "    for j, (u, x) in enumerate(zip([U_s, U_pH_T], [X_s, X_pH_T])):\n",
    "        plot_scores(axes=axes[2*j:2*j+2,i], U=u, z_train=z_task, accuracies=accuracies_all[i][j], test_scores=test_scores_all[i][j], test_scores_std=test_scores_std_all[i][j])\n",
    "\n",
    "axes[1,1].set_ylabel('')\n",
    "axes[1,2].set_ylabel('')\n",
    "axes[3,1].set_ylabel('')\n",
    "axes[3,2].set_ylabel('')\n",
    "\n",
    "for i in range(3):\n",
    "    axes[0,i].set_xticks([])\n",
    "    axes[0,i].set_yticks([])\n",
    "    axes[2,i].set_xticks([])\n",
    "    axes[2,i].set_yticks([])\n",
    "    axes[1,i].set_ylim(0, 1.05)\n",
    "    axes[3,i].set_ylim(0, 1.05)\n",
    "    axes[1,i].set_yticks([0, 0.5, 1.0], [])\n",
    "    axes[3,i].set_yticks([0, 0.5, 1.0], [])\n",
    "axes[1,0].set_yticks([0, 0.5, 1.0], [0, 0.5, 1.0])\n",
    "axes[3,0].set_yticks([0, 0.5, 1.0], [0, 0.5, 1.0])\n",
    "\n",
    "plt.savefig(f\"../plots/sensor_results.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores_all_extended = [[None, None, None, None] for _ in range(len(y_extended))]\n",
    "test_scores_std_all_extended = [[None, None, None, None] for _ in range(len(y_extended))]\n",
    "accuracies_all_extended = [[None, None, None, None] for _ in range(len(y_extended))]\n",
    "for i, (y_task, z_task) in enumerate(zip(y_extended.values(), z_extended.values())):\n",
    "    for j, (u, x) in enumerate(zip([U_s, U_pH_T, U_pH_S2, U_T_S2], [X_s, X_pH_T, X_pH_S2, X_T_S2])):\n",
    "        y_pred, accuracies, train_scores, test_scores, test_scores_std = classification_task(u, x, y_task=y_task(u), n_repeats=10,)\n",
    "        test_scores_all_extended[i][j] = test_scores\n",
    "        test_scores_std_all_extended[i][j] = test_scores_std\n",
    "        accuracies_all_extended[i][j] = accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(8,10, figsize=(8, 5), constrained_layout=False, gridspec_kw={'height_ratios':[2,1,2,1, 2,1, 2,1]})\n",
    "for i, (y_task, z_task) in enumerate(zip(y_extended.values(), z_extended.values())):\n",
    "    for j, (u, x) in enumerate(zip([U_s, U_pH_T, U_pH_S2, U_T_S2], [X_s, X_pH_T, X_pH_S2, X_T_S2])):\n",
    "        plot_scores(axes=axes[2*j:2*j+2,i], U=u, z_train=z_task, accuracies=accuracies_all_extended[i][j], test_scores=test_scores_all_extended[i][j], test_scores_std=test_scores_std_all_extended[i][j])\n",
    "\n",
    "cmap = sns.color_palette(\"blend:#BF616A,#EBCB8B,#8FBCBB\", as_cmap=True, n_colors=10)\n",
    "\n",
    "for i in range(len(y_extended)):\n",
    "    axes[0,i].set_xticks([])\n",
    "    axes[0,i].set_yticks([])\n",
    "    axes[2,i].set_xticks([])\n",
    "    axes[2,i].set_yticks([])\n",
    "    axes[4,i].set_xticks([])\n",
    "    axes[4,i].set_yticks([])\n",
    "    axes[6,i].set_xticks([])\n",
    "    axes[6,i].set_yticks([])\n",
    "    axes[1,i].set_ylabel('')\n",
    "    axes[3,i].set_ylabel('')\n",
    "    axes[5,i].set_ylabel('')\n",
    "    axes[7,i].set_ylabel('')\n",
    "    axes[1,i].set_ylim(0, 1.05)\n",
    "    axes[3,i].set_ylim(0, 1.05)\n",
    "    axes[1,i].set_yticks([0, 0.5, 1.0], [])\n",
    "    axes[3,i].set_yticks([0, 0.5, 1.0], [])\n",
    "    axes[5,i].set_ylim(0, 1.05)\n",
    "    axes[7,i].set_ylim(0, 1.05)\n",
    "    axes[5,i].set_yticks([0, 0.5, 1.0], [])\n",
    "    axes[7,i].set_yticks([0, 0.5, 1.0], [])\n",
    "\n",
    "axes[1,0].set_yticks([0, 0.5, 1.0], [0, 0.5, 1.0])\n",
    "axes[3,0].set_yticks([0, 0.5, 1.0], [0, 0.5, 1.0])\n",
    "axes[5,0].set_yticks([0, 0.5, 1.0], [0, 0.5, 1.0])\n",
    "axes[7,0].set_yticks([0, 0.5, 1.0], [0, 0.5, 1.0])\n",
    "\n",
    "axes[1,0].set_ylabel('S1 vs S2')\n",
    "axes[3,0].set_ylabel('pH vs T')\n",
    "axes[5,0].set_ylabel('pH vs S2')\n",
    "axes[7,0].set_ylabel('T vs S2')\n",
    "\n",
    "plt.savefig(f\"../plots/SI_sensor_results_extended.svg\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
